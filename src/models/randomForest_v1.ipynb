{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "\n",
    "# random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading in \n",
    "df = pd.read_csv('full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6607, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>stance</th>\n",
       "      <th>gender</th>\n",
       "      <th>temperature_avg</th>\n",
       "      <th>aggressiveness</th>\n",
       "      <th>text</th>\n",
       "      <th>Full_Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Continent</th>\n",
       "      <th>Country</th>\n",
       "      <th>State</th>\n",
       "      <th>is_english</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2008-03-28 14:15:51+00:00</td>\n",
       "      <td>778602262</td>\n",
       "      <td>-93.101503</td>\n",
       "      <td>44.950404</td>\n",
       "      <td>Importance of Human Intervantion</td>\n",
       "      <td>-0.042726</td>\n",
       "      <td>believer</td>\n",
       "      <td>male</td>\n",
       "      <td>-4.082745</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>on march 29, 2008 at 8 pm, make a statement ab...</td>\n",
       "      <td>{'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...</td>\n",
       "      <td>Saint Paul</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-03-28 15:36:30+00:00</td>\n",
       "      <td>778649364</td>\n",
       "      <td>-117.164720</td>\n",
       "      <td>32.715710</td>\n",
       "      <td>Global stance</td>\n",
       "      <td>0.429441</td>\n",
       "      <td>believer</td>\n",
       "      <td>undefined</td>\n",
       "      <td>-0.132076</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>City looks at green building standards: Hoping...</td>\n",
       "      <td>{'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-03-28 15:41:13+00:00</td>\n",
       "      <td>778652293</td>\n",
       "      <td>-122.355847</td>\n",
       "      <td>37.788497</td>\n",
       "      <td>Weather Extremes</td>\n",
       "      <td>0.092446</td>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>-2.324198</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>@thiskat @agray @payload Snow? In PDX? In Marc...</td>\n",
       "      <td>{'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-03-28 15:56:42+00:00</td>\n",
       "      <td>778661751</td>\n",
       "      <td>-123.033121</td>\n",
       "      <td>44.939157</td>\n",
       "      <td>Ideological Positions on Global Warming</td>\n",
       "      <td>-0.337010</td>\n",
       "      <td>denier</td>\n",
       "      <td>male</td>\n",
       "      <td>-4.810226</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>someone alert al gore - global warming isn't w...</td>\n",
       "      <td>{'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...</td>\n",
       "      <td>Salem</td>\n",
       "      <td>North America</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-03-28 16:09:12+00:00</td>\n",
       "      <td>778669248</td>\n",
       "      <td>-123.364953</td>\n",
       "      <td>48.428318</td>\n",
       "      <td>Weather Extremes</td>\n",
       "      <td>-0.317469</td>\n",
       "      <td>denier</td>\n",
       "      <td>male</td>\n",
       "      <td>-4.862617</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>It's snowing in Langford and sticking!  It's t...</td>\n",
       "      <td>{'ISO_3166-1_alpha-2': 'CA', 'ISO_3166-1_alpha...</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>North America</td>\n",
       "      <td>Canada</td>\n",
       "      <td>British Columbia</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 created_at         id         lng        lat  \\\n",
       "0           0  2008-03-28 14:15:51+00:00  778602262  -93.101503  44.950404   \n",
       "1           1  2008-03-28 15:36:30+00:00  778649364 -117.164720  32.715710   \n",
       "2           2  2008-03-28 15:41:13+00:00  778652293 -122.355847  37.788497   \n",
       "3           3  2008-03-28 15:56:42+00:00  778661751 -123.033121  44.939157   \n",
       "4           4  2008-03-28 16:09:12+00:00  778669248 -123.364953  48.428318   \n",
       "\n",
       "                                     topic  sentiment    stance     gender  \\\n",
       "0         Importance of Human Intervantion  -0.042726  believer       male   \n",
       "1                            Global stance   0.429441  believer  undefined   \n",
       "2                         Weather Extremes   0.092446   neutral       male   \n",
       "3  Ideological Positions on Global Warming  -0.337010    denier       male   \n",
       "4                         Weather Extremes  -0.317469    denier       male   \n",
       "\n",
       "   temperature_avg  aggressiveness  \\\n",
       "0        -4.082745      aggressive   \n",
       "1        -0.132076  not aggressive   \n",
       "2        -2.324198  not aggressive   \n",
       "3        -4.810226  not aggressive   \n",
       "4        -4.862617  not aggressive   \n",
       "\n",
       "                                                text  \\\n",
       "0  on march 29, 2008 at 8 pm, make a statement ab...   \n",
       "1  City looks at green building standards: Hoping...   \n",
       "2  @thiskat @agray @payload Snow? In PDX? In Marc...   \n",
       "3  someone alert al gore - global warming isn't w...   \n",
       "4  It's snowing in Langford and sticking!  It's t...   \n",
       "\n",
       "                                        Full_Address           City  \\\n",
       "0  {'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...     Saint Paul   \n",
       "1  {'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...      San Diego   \n",
       "2  {'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...  San Francisco   \n",
       "3  {'ISO_3166-1_alpha-2': 'US', 'ISO_3166-1_alpha...          Salem   \n",
       "4  {'ISO_3166-1_alpha-2': 'CA', 'ISO_3166-1_alpha...       Victoria   \n",
       "\n",
       "       Continent        Country             State is_english  \n",
       "0  North America  United States         Minnesota       True  \n",
       "1  North America  United States        California       True  \n",
       "2  North America  United States        California       True  \n",
       "3  North America  United States            Oregon      False  \n",
       "4  North America         Canada  British Columbia       True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at df\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 1014 Negative: 1021 Neutral: 4572\n"
     ]
    }
   ],
   "source": [
    "# looking at sentiments \n",
    "pos = (df['sentiment'] > 0.5).sum()\n",
    "neg = (df['sentiment'] < -0.5).sum()\n",
    "neutral = len(df) - pos - neg\n",
    "print(f'Positive: {pos} Negative: {neg} Neutral: {neutral}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logic to create classes for sentiment\n",
    "sentiment  = df[\"sentiment\"]\n",
    "\n",
    "conditions = [sentiment >= 0.5,\n",
    "              sentiment <= -0.5,\n",
    "              (sentiment >-0.5) & (sentiment <0.5)]\n",
    "choices  = [2,0,1]\n",
    "\n",
    "# create a new column in the DF based on the conditions\n",
    "df[\"label\"] = np.select(conditions, choices, \"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>stance</th>\n",
       "      <th>gender</th>\n",
       "      <th>aggressiveness</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Importance of Human Intervantion</td>\n",
       "      <td>believer</td>\n",
       "      <td>male</td>\n",
       "      <td>aggressive</td>\n",
       "      <td>on march 29, 2008 at 8 pm, make a statement ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global stance</td>\n",
       "      <td>believer</td>\n",
       "      <td>undefined</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>City looks at green building standards: Hoping...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Weather Extremes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>male</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>@thiskat @agray @payload Snow? In PDX? In Marc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ideological Positions on Global Warming</td>\n",
       "      <td>denier</td>\n",
       "      <td>male</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>someone alert al gore - global warming isn't w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Weather Extremes</td>\n",
       "      <td>denier</td>\n",
       "      <td>male</td>\n",
       "      <td>not aggressive</td>\n",
       "      <td>It's snowing in Langford and sticking!  It's t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     topic    stance     gender  \\\n",
       "0         Importance of Human Intervantion  believer       male   \n",
       "1                            Global stance  believer  undefined   \n",
       "2                         Weather Extremes   neutral       male   \n",
       "3  Ideological Positions on Global Warming    denier       male   \n",
       "4                         Weather Extremes    denier       male   \n",
       "\n",
       "   aggressiveness                                               text  label  \n",
       "0      aggressive  on march 29, 2008 at 8 pm, make a statement ab...      1  \n",
       "1  not aggressive  City looks at green building standards: Hoping...      1  \n",
       "2  not aggressive  @thiskat @agray @payload Snow? In PDX? In Marc...      1  \n",
       "3  not aggressive  someone alert al gore - global warming isn't w...      1  \n",
       "4  not aggressive  It's snowing in Langford and sticking!  It's t...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking it out\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "df = df.drop('sentiment', axis=1)\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# dropping unwanted columns\n",
    "df = df.drop('id', axis=1)\n",
    "df = df.drop('lng', axis=1)\n",
    "df = df.drop('Full_Address', axis=1)\n",
    "df = df.drop('lat', axis=1)\n",
    "df = df.drop('temperature_avg', axis=1)\n",
    "df = df.drop('is_english', axis=1)\n",
    "df = df.drop('created_at', axis=1)\n",
    "df = df.drop('Country', axis=1)\n",
    "df = df.drop('Continent', axis=1)\n",
    "df = df.drop('City', axis=1)\n",
    "df = df.drop('State', axis=1)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6607, 6)\n"
     ]
    }
   ],
   "source": [
    "# loooking at shape again\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# splitting the data into independent and dependent variables\u001b[39;00m\n\u001b[0;32m      2\u001b[0m X \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m8\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m----> 3\u001b[0m y \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m9\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe independent features set: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(X[:\u001b[38;5;241m10\u001b[39m,:])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1097\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1096\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1594\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1593\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, tup: \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m-> 1594\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1596\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_lowerdim(tup)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:904\u001b[0m, in \u001b[0;36m_LocationIndexer._validate_tuple_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(key):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 904\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(k, i)\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    907\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocation based indexing can only have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    908\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_valid_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] types\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1496\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_key\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1494\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(key):\n\u001b[1;32m-> 1496\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m   1498\u001b[0m     \u001b[38;5;66;03m# a tuple should already have been caught by this point\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m     \u001b[38;5;66;03m# so don't treat a tuple as a valid indexer\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToo many indexers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1587\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1589\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# splitting the data into independent and dependent variables\n",
    "X = df.iloc[:,0:8].values\n",
    "y = df.iloc[:,9].values\n",
    "print('The independent features set: ')\n",
    "print(X[:10,:])\n",
    "print('The dependent variable: ')\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 21)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.90, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size = 0.5, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size = 0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding \n",
    "from sklearn import preprocessing\n",
    "\n",
    "cols = ['topic', 'stance', 'gender', 'aggressiveness', 'City', 'Continent', 'Country', 'State']\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head\n",
    "a = df['Country'].unique()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero\n",
    "df['tfidf'] = hero.tfidf(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train = scaler.fit_transform(X_train_tfidf)\n",
    "X_test = scaler.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
    "classifier.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "definitions = ['topic', 'stance', 'gender', 'aggressiveness', 'text', 'City', 'Continent', 'Country', 'State']\n",
    "y_pred = classifier.predict(X_test)\n",
    "reversefactor = dict(zip(range(3),definitions))\n",
    "y_test = np.vectorize(reversefactor.get)(y_test)\n",
    "y_pred = np.vectorize(reversefactor.get)(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
